## NLP-Natural-Language-Processing

### Step 1.Text Preprocessing Level-1 : 
Remove Special Characters, Convert Lowercase, Stop word removal, Tokenization, Lemmatization, Stemming
#### Description
In NLP, we have the text data, which our Machine Learning algorithms cannot directly use, so we have first to preprocess it and then feed the preprocessed data to our Machine Learning algorithms. So, In this step, we will try to learn the same basic processing steps which we have to perform in almost every NLP problem.
### Step 2. Advanced level Text Cleaning:
üëâ Normalization,
üëâ Correction of Typos, etc.

#### Description
These advanced-level techniques help our text data give our model better performance. Let‚Äôs take an advanced understanding of some of these techniques straightforwardly.
##### Normalization:
Map the words to a fixed language word.
For Example, according to human beings, Let‚Äôs have words like b4, and ttyl which can be understood as ‚Äúbefore‚Äù and ‚Äútalk to you later‚Äù respectively. Still, machines cannot understand these words the same way, so we have to map these words to a particular language word. This map is known as Normalization.

##### Correction of typos:
There are a lot of mistakes in writing English text or for other languages text, like Fen instead of a fan. The accurate map necessitates using a dictionary, which we used to map words to their correct forms based on similarity. Correction of typos is the term for this procedure.
### Step 3.Text Preprocessing Level-2(word to vec): 
üëâ Bag Of Words(BOW), 
üëâ TFIDF, 
üëâ Unigrams, Bigrams, and Ngrams  
#### Description:
    All these are the primary methods to convert our Text data into numerical data (Vectors) to apply a Machine Learning algorithm to it. 
### Step 4. Text Preprocessing Level-3:  
Word2vec, AvgWord2vec, Glove, Fast Text
#### Description
    All these are advanced techniques to convert words into vectors.
### Step 5. Solve Machine Learning Use cases
    Hands-on Experience on a use case
#### Description 
    After following all the above steps, now at this step, you can implement a typical or straightforward NLP use case using machine learning algorithms like Naive Bayes Classifier, etc. To have a clear understanding of all the above and understand the next steps.
Email Spam or Ham classification
### Step 6. Get an advanced level understanding of Artificial Neural Network
    While going much deeper into NLP, you do not take Artificial Neural Networks (ANN) very far from your view; you have to know about the basic deep learning algorithms, including backpropagation, gradient descent, etc.
### Step 7. Deep Learning Models:
RNN, LSTM RNN, GRU RNN 
    RNN is mainly used when we have the data sequence in hand, and we have to analyze that data. We will understand LSTM and GRU, conceptually succeeding topics after RNN.
### Step 8.Advanced Text Preprocessing level -4:
Word Embedding,
Word2Vec
    Now, we can do moderate-level projects related to NLP and makeproso in this domain. Below are some stepsthat will differentiate you from otherse who have also worked in this field. So, to take an edge over all those people learning these topics are a must.
### Step 9:
Bidirectional LSTM RNN, Encoders, and Decoders, Self Attention Models
    
### Step 10.
Transformers Learning in NLP
    The Transformer in NLP is an architecture that seeks to handle sequence-to-sequence tasks while handling long-range relationships with ease. It leverages self-attention models.
### Step 11:
üëâ BERT(Bidirectional Encoder Representations from Transformers)

Description 
    It is a variation of the transformer, and it converts a sentence into a vector. It is a neural network-based technique used for natural language processing pre-training.
